{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENEN90032 - Environmental Analysis Tools\n",
    "## Major Assignment #1 - Individual Assignment\n",
    "Prepared by: Michael Kimani Gathogo (CS-CNS03-23111)\n",
    "\n",
    "---\n",
    "This notebook contains all solutions (Q1â€“Q6) for the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Exploratory Data Analysis - Meteorological Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Perth   Brisbane  Melbourne\n",
      "Mean          7.503846  11.341353   7.949275\n",
      "Median        4.450000   4.400000   5.200000\n",
      "Trimean       5.112500   5.800000   5.575000\n",
      "Std Dev       8.790586  20.373137   8.507654\n",
      "IQR           7.550000  10.800000   6.700000\n",
      "MAD           3.000000   3.600000   2.800000\n",
      "Skewness      2.305587   5.463579   2.280701\n",
      "Yule-Kendall  0.350993   0.518519   0.223881\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load rainfall datasets (replace with actual file paths)\n",
    "perth = pd.read_csv('data/perth_IDCJAC0009_091021_2024_Data.csv')\n",
    "brisbane = pd.read_csv('data/brisbane_IDCJAC0009_040224_2024_Data.csv')\n",
    "melbourne = pd.read_csv('data/melbourne_IDCJAC0009_086304_2024_Data.csv')\n",
    "\n",
    "def preprocess_rainfall(df):\n",
    "    col = 'Rainfall amount (millimetres)'\n",
    "    return df[df[col] > 0.25][col].dropna()\n",
    "\n",
    "datasets = {\n",
    "    'Perth': preprocess_rainfall(perth),\n",
    "    'Brisbane': preprocess_rainfall(brisbane),\n",
    "    'Melbourne': preprocess_rainfall(melbourne)\n",
    "}\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = {}\n",
    "for city, data in datasets.items():\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    trimean = (np.percentile(data, 25) + 2*median + np.percentile(data, 75)) / 4\n",
    "    std = np.std(data, ddof=1)\n",
    "    iqr = stats.iqr(data)\n",
    "    mad = stats.median_abs_deviation(data)\n",
    "    skew = stats.skew(data)\n",
    "    q1, q3 = np.percentile(data, [25, 75])\n",
    "    yk_index = (q3 + q1 - 2*median) / (q3 - q1)\n",
    "    summary_stats[city] = [mean, median, trimean, std, iqr, mad, skew, yk_index]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats, index=['Mean','Median','Trimean','Std Dev','IQR','MAD','Skewness','Yule-Kendall'])\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Hypothesis Test - Newcomb-Michelson Velocity of Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data/NewcombLight.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/NewcombLight.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m distance = \u001b[32m7442\u001b[39m  \u001b[38;5;66;03m# meters\u001b[39;00m\n\u001b[32m      3\u001b[39m velocities = distance / data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataAnalysis/venv/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:1397\u001b[39m, in \u001b[36mloadtxt\u001b[39m\u001b[34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[39m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1395\u001b[39m     delimiter = delimiter.decode(\u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m arr = \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[43m=\u001b[49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataAnalysis/venv/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:1024\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[39m\n\u001b[32m   1022\u001b[39m     fname = os.fspath(fname)\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     fh = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_datasource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1026\u001b[39m         encoding = \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataAnalysis/venv/lib/python3.13/site-packages/numpy/lib/_datasource.py:192\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(path, mode, destpath, encoding, newline)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[32m    157\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \n\u001b[32m    189\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    191\u001b[39m ds = DataSource(destpath)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataAnalysis/venv/lib/python3.13/site-packages/numpy/lib/_datasource.py:529\u001b[39m, in \u001b[36mDataSource.open\u001b[39m\u001b[34m(self, path, mode, encoding, newline)\u001b[39m\n\u001b[32m    526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode=mode,\n\u001b[32m    527\u001b[39m                               encoding=encoding, newline=newline)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m529\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: data/NewcombLight.txt not found."
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/NewcombLight.txt')\n",
    "distance = 7442  # meters\n",
    "velocities = distance / data\n",
    "\n",
    "# t-test\n",
    "t_stat, p_val = stats.ttest_1samp(velocities, 299792458)\n",
    "print('T-test statistic:', t_stat, 'p-value:', p_val)\n",
    "\n",
    "# 95% CI (t-test)\n",
    "mean = np.mean(velocities)\n",
    "se = stats.sem(velocities)\n",
    "ci = stats.t.interval(0.95, len(velocities)-1, loc=mean, scale=se)\n",
    "print('95% CI (t-test):', ci)\n",
    "\n",
    "# Bootstrap\n",
    "np.random.seed(42)\n",
    "boot_means = [np.mean(np.random.choice(velocities, size=len(velocities), replace=True)) for _ in range(10000)]\n",
    "ci_boot = np.percentile(boot_means, [2.5, 97.5])\n",
    "print('95% CI (bootstrap):', ci_boot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Daily Max Temperature at Avalon and Moorabbin Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalon = pd.read_csv('data/avalon_temp.csv')\n",
    "moorabbin = pd.read_csv('data/moorabbin_temp.csv')\n",
    "\n",
    "# Drop missing days\n",
    "avalon = avalon.dropna()\n",
    "moorabbin = moorabbin.dropna()\n",
    "\n",
    "# Two-sample t-test\n",
    "t_stat, p_val = stats.ttest_ind(avalon['temp'], moorabbin['temp'], equal_var=False)\n",
    "print('t-statistic:', t_stat, 'p-value:', p_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Hypothesis Test - Space Shuttle O-Ring Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oring = pd.read_excel('data/O_Ring_Data.xls')\n",
    "cool = oring[oring['Condition']=='COOL']['Incidents']\n",
    "warm = oring[oring['Condition']=='WARM']['Incidents']\n",
    "\n",
    "# Observed difference\n",
    "obs_diff = np.mean(cool) - np.mean(warm)\n",
    "\n",
    "# Permutation test\n",
    "combined = np.concatenate([cool, warm])\n",
    "np.random.seed(42)\n",
    "perm_diffs = []\n",
    "for _ in range(10000):\n",
    "    np.random.shuffle(combined)\n",
    "    new_cool = combined[:len(cool)]\n",
    "    new_warm = combined[len(cool):]\n",
    "    perm_diffs.append(np.mean(new_cool) - np.mean(new_warm))\n",
    "\n",
    "ci = np.percentile(perm_diffs, [0.5, 99.5])\n",
    "print('Observed diff:', obs_diff, 'Permutation 99% CI:', ci)\n",
    "\n",
    "plt.hist(perm_diffs, bins=30, alpha=0.7)\n",
    "plt.axvline(obs_diff, color='red', linestyle='dashed', label='Observed diff')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Cloud Seeding Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = pd.read_excel('data/Cloud_Seeding_Case_Study.xls')\n",
    "seeded = cloud[cloud['Seeded']==1]['Rainfall']\n",
    "unseeded = cloud[cloud['Seeded']==0]['Rainfall']\n",
    "\n",
    "# Parametric test\n",
    "t_stat, p_val = stats.ttest_ind(seeded, unseeded, equal_var=False)\n",
    "print('t-statistic:', t_stat, 'p-value:', p_val)\n",
    "\n",
    "# Permutation test\n",
    "combined = np.concatenate([seeded, unseeded])\n",
    "obs_diff = np.mean(seeded) - np.mean(unseeded)\n",
    "perm_diffs = []\n",
    "for _ in range(10000):\n",
    "    np.random.shuffle(combined)\n",
    "    new_seeded = combined[:len(seeded)]\n",
    "    new_unseeded = combined[len(seeded):]\n",
    "    perm_diffs.append(np.mean(new_seeded) - np.mean(new_unseeded))\n",
    "\n",
    "ci_perm = np.percentile(perm_diffs, [2.5, 97.5])\n",
    "print('Observed diff:', obs_diff, 'Permutation 95% CI:', ci_perm)\n",
    "\n",
    "# Log transform\n",
    "seeded_log = np.log(seeded)\n",
    "unseeded_log = np.log(unseeded)\n",
    "t_stat_log, p_val_log = stats.ttest_ind(seeded_log, unseeded_log, equal_var=False)\n",
    "print('Log-transformed t-test:', t_stat_log, 'p-value:', p_val_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Exploratory Data Analysis and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qtkn = pd.read_csv('data/Q_TKN_data.csv')\n",
    "Q = data_qtkn['Q']\n",
    "TKN = data_qtkn['TKN']\n",
    "\n",
    "# Correlations\n",
    "pearson = stats.pearsonr(Q, TKN)\n",
    "spearman = stats.spearmanr(Q, TKN)\n",
    "print('Pearson:', pearson, 'Spearman:', spearman)\n",
    "\n",
    "# Log-transform\n",
    "logQ = np.log(Q)\n",
    "logTKN = np.log(TKN)\n",
    "pearson_log = stats.pearsonr(logQ, logTKN)\n",
    "spearman_log = stats.spearmanr(logQ, logTKN)\n",
    "print('Log Pearson:', pearson_log, 'Log Spearman:', spearman_log)\n",
    "\n",
    "# Linear regression\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(logQ)\n",
    "model = sm.OLS(logTKN, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Predict TKN when Q=2 mm/d\n",
    "pred_log = model.predict([1, np.log(2)])\n",
    "pred = np.exp(pred_log)\n",
    "print('Predicted TKN at Q=2:', pred)\n",
    "\n",
    "# Residuals\n",
    "residuals = model.resid\n",
    "plt.scatter(logQ, residuals)\n",
    "plt.axhline(0, color='red')\n",
    "plt.title('Residuals vs logQ')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
