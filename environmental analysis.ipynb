{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56b52ed",
   "metadata": {},
   "source": [
    "# ENEN90032 - Environmental Analysis Tools\n",
    "## Assignment #1 - Individual Assignment\n",
    "\n",
    "---\n",
    "This notebook contains all solutions from question 1 to 6 for this assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe4446",
   "metadata": {},
   "source": [
    "# ENEN90032 — Assignment #1 (Part 1)\n",
    "**Instructions:** All the data files are in the `data/` folder. Make sure you run the notebook top-to-bottom. You may also run cell by cell.\n",
    "\n",
    "**Notes:** Each question restricts libraries; I have used only the allowed libraries per question in the corresponding cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2279aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and file paths for the statistical analysis tasks\n",
    "# Datasets for Q1 rainfall CSVs (wet-day analysis; any filename is fine as long as it has a date column and rainfall column)\n",
    "PERTH_RAIN_CSV = \"data/perth_IDCJAC0009_091021_2024_Data.csv\"\n",
    "BRISBANE_RAIN_CSV = \"data/brisbane_IDCJAC0009_040224_2024_Data.csv\"\n",
    "MELBOURNE_RAIN_CSV = \"data/melbourne_IDCJAC0009_086304_2024_Data.csv\"\n",
    "\n",
    "# Datasets for Q2 Newcomb data (time in seconds for 7442 m)\n",
    "NEWCOMB_TXT = \"data/NewcombLight.txt\"\n",
    "\n",
    "# Datasets for Q3 Tmax Avalon and Moorabbin (daily max temp 2024)\n",
    "AVALON_TMAX_CSV = \"data/AVALON_087113_2024.csv\"\n",
    "MOORABBIN_TMAX_CSV = \"data/MOORABBIN_086077_2024.csv\"\n",
    "\n",
    "# Datasets for Q4 O-ring data (xls or csv)\n",
    "ORING_DATA = \"data/O_Ring_Data.xls\"\n",
    "\n",
    "# Datasets for Q5 Cloud seeding (xls or csv)\n",
    "CLOUDSEED_DATA = \"data/Cloud_Seeding_Case_Study.xls\"\n",
    "\n",
    "# Datasets for Q6 Q-TKN data (csv)\n",
    "QTKN_DATA = \"data/Q_TKN_data.csv\"\n",
    "\n",
    "# General parameters\n",
    "YEAR = 2024\n",
    "DETECTION_LIMIT_MM = 0.25\n",
    "RANGE_RANDOM_SEED = 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dcfd9a",
   "metadata": {},
   "source": [
    "# ENEN90032 — Question #1 - Exploratory Data Analysis - Meteorological Datasets\n",
    "\n",
    "**Allowed and the used libraries are;** numpy, pandas, matplotlib, scipy.stats, math, statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9dda686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# customize the default appearance of plots generated by Matplotlib\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "plt.rcParams['figure.figsize'] = (7,4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3490025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Summary Results ---\n",
      "\n",
      "City: Perth\n",
      "  n_wetdays: 78\n",
      "  mean: 7.504\n",
      "  median: 4.450\n",
      "  trimean: 5.113\n",
      "  std: 8.791\n",
      "  IQR: 7.550\n",
      "  MAD: 3.000\n",
      "  skewness: 2.351\n",
      "  yule_kendall: 0.351\n",
      "\n",
      "City: Brisbane\n",
      "  n_wetdays: 133\n",
      "  mean: 11.341\n",
      "  median: 4.400\n",
      "  trimean: 5.800\n",
      "  std: 20.373\n",
      "  IQR: 10.800\n",
      "  MAD: 3.600\n",
      "  skewness: 5.526\n",
      "  yule_kendall: 0.519\n",
      "\n",
      "City: Melbourne\n",
      "  n_wetdays: 69\n",
      "  mean: 7.949\n",
      "  median: 5.200\n",
      "  trimean: 5.575\n",
      "  std: 8.508\n",
      "  IQR: 6.700\n",
      "  MAD: 2.800\n",
      "  skewness: 2.332\n",
      "  yule_kendall: 0.224\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "DETECTION_LIMIT_MM = DETECTION_LIMIT_MM\n",
    "YEAR = YEAR\n",
    "\n",
    "def _find_date_col(df):\n",
    "    candidates = [c for c in df.columns if 'date' in c.lower()]\n",
    "    if candidates:\n",
    "        return candidates[0]\n",
    "    return df.columns[0]\n",
    "\n",
    "def _find_rain_col(df):\n",
    "    for c in df.columns:\n",
    "        if 'rain' in c.lower():\n",
    "            return c\n",
    "    raise ValueError(\"No rain column found. Make sure filename has a column with 'rain' in header.\")\n",
    "\n",
    "def load_rain_csv(path, detection_limit=DETECTION_LIMIT_MM, year=YEAR):\n",
    "    df = pd.read_csv(path)\n",
    "    date_col = _find_date_col(df)\n",
    "    rain_col = _find_rain_col(df)\n",
    "    df = df.rename(columns={date_col: 'date', rain_col: 'rain_mm'})\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df = df[df['date'].dt.year == year].copy()\n",
    "    df['rain_mm'] = pd.to_numeric(df['rain_mm'], errors='coerce')\n",
    "    missing = df['rain_mm'].isna().sum()\n",
    "    # Drop missing and apply wet-day filter\n",
    "    df = df.dropna(subset=['rain_mm'])\n",
    "    df = df[df['rain_mm'] >= detection_limit].sort_values('date').reset_index(drop=True)\n",
    "    return df, missing\n",
    "\n",
    "def trimean(x):\n",
    "    q1, med, q3 = np.percentile(x, [25,50,75])\n",
    "    return (q1 + 2*med + q3)/4.0\n",
    "\n",
    "def iqr(x):\n",
    "    q1, q3 = np.percentile(x, [25,75])\n",
    "    return q3 - q1\n",
    "\n",
    "def mad(x):\n",
    "    med = np.median(x)\n",
    "    return np.median(np.abs(x - med))\n",
    "\n",
    "def yule_kendall(x):\n",
    "    q1, med, q3 = np.percentile(x, [25,50,75])\n",
    "    denom = (q3 - q1)\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return (q3 + q1 - 2*med) / denom\n",
    "\n",
    "def summarize(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return dict(\n",
    "        n_wetdays = x.size,\n",
    "        mean = float(np.mean(x)),\n",
    "        median = float(np.median(x)),\n",
    "        trimean = float(trimean(x)),\n",
    "        std = float(np.std(x, ddof=1)) if x.size>1 else np.nan,\n",
    "        IQR = float(iqr(x)),\n",
    "        MAD = float(mad(x)),\n",
    "        skewness = float(stats.skew(x, bias=False)) if x.size>3 else np.nan,\n",
    "        yule_kendall = float(yule_kendall(x))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # --- Constants ---\n",
    "# DETECTION_LIMIT_MM = DETECTION_LIMIT_MM\n",
    "# YEAR = YEAR\n",
    "\n",
    "# # --- Utility Functions ---\n",
    "# def _find_date_col(df):\n",
    "#     \"\"\"Identifies the date column based on common keywords.\"\"\"\n",
    "#     for col in df.columns:\n",
    "#         if 'date' in col.lower() or 'observation' in col.lower():\n",
    "#             return col\n",
    "#     raise ValueError(\"No suitable date column found in the dataset.\")\n",
    "\n",
    "# def _find_rain_col(df):\n",
    "#     \"\"\"Identifies the rainfall column based on common keywords.\"\"\"\n",
    "#     for col in df.columns:\n",
    "#         if 'rain' in col.lower() and ('mm' in col.lower() or 'amount' in col.lower()):\n",
    "#             return col\n",
    "#     raise ValueError(\"No suitable rainfall column found in the dataset.\")\n",
    "\n",
    "# def load_rain_csv(path, detection_limit=DETECTION_LIMIT_MM, year=YEAR):\n",
    "#     \"\"\"\n",
    "#     Loads and preprocesses rainfall data from a CSV file.\n",
    "    \n",
    "#     Args:\n",
    "#         path (str): The path to the CSV file.\n",
    "#         detection_limit (float): The minimum rainfall amount to consider a \"wet day\".\n",
    "#         year (int): The year to filter the data for.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: A tuple containing the preprocessed DataFrame and the count of missing values.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         df = pd.read_csv(path, comment='#')\n",
    "#         df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
    "        \n",
    "#         date_col = _find_date_col(df)\n",
    "#         rain_col = _find_rain_col(df)\n",
    "        \n",
    "#         df = df.rename(columns={date_col: 'date', rain_col: 'rain_mm'})\n",
    "        \n",
    "#         df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "#         df = df.dropna(subset=['date'])\n",
    "        \n",
    "#         df['rain_mm'] = pd.to_numeric(df['rain_mm'], errors='coerce')\n",
    "#         missing_values = df['rain_mm'].isna().sum()\n",
    "        \n",
    "#         # Filter for the specified year and wet days\n",
    "#         df = df[(df['date'].dt.year == year) & (df['rain_mm'].notna())].copy()\n",
    "#         wet_days = df[df['rain_mm'] >= detection_limit].reset_index(drop=True)\n",
    "        \n",
    "#         return wet_days, missing_values\n",
    "#     except (FileNotFoundError, ValueError) as e:\n",
    "#         print(f\"Error processing {path}: {e}\")\n",
    "#         return pd.DataFrame(), 0\n",
    "\n",
    "# def trimean(x):\n",
    "#     \"\"\"Calculates the trimean for a given array.\"\"\"\n",
    "#     q1, med, q3 = np.percentile(x, [25, 50, 75])\n",
    "#     return (q1 + 2 * med + q3) / 4.0\n",
    "\n",
    "# def iqr(x):\n",
    "#     \"\"\"Calculates the Interquartile Range (IQR).\"\"\"\n",
    "#     q1, q3 = np.percentile(x, [25, 75])\n",
    "#     return q3 - q1\n",
    "\n",
    "# def mad(x):\n",
    "#     \"\"\"Calculates the Median Absolute Deviation (MAD).\"\"\"\n",
    "#     med = np.median(x)\n",
    "#     return np.median(np.abs(x - med))\n",
    "\n",
    "# def yule_kendall(x):\n",
    "#     \"\"\"Calculates the Yule-Kendall index.\"\"\"\n",
    "#     q1, med, q3 = np.percentile(x, [25, 50, 75])\n",
    "#     denom = (q3 - q1)\n",
    "#     if denom == 0:\n",
    "#         return np.nan\n",
    "#     return (q3 + q1 - 2 * med) / denom\n",
    "\n",
    "# def summarize(x):\n",
    "#     \"\"\"\n",
    "#     Calculates and returns a dictionary of summary statistics.\n",
    "    \n",
    "#     Args:\n",
    "#         x (pd.Series or np.ndarray): The data to summarize.\n",
    "        \n",
    "#     Returns:\n",
    "#         dict: A dictionary of summary statistics.\n",
    "#     \"\"\"\n",
    "#     x = np.asarray(x, dtype=float)\n",
    "#     if x.size < 4:\n",
    "#         # Avoid errors with small datasets for skewness\n",
    "#         skewness_val = np.nan\n",
    "#     else:\n",
    "#         skewness_val = float(stats.skew(x, bias=False))\n",
    "\n",
    "#     return {\n",
    "#         'n_wetdays': x.size,\n",
    "#         'mean': float(np.mean(x)) if x.size > 0 else np.nan,\n",
    "#         'median': float(np.median(x)) if x.size > 0 else np.nan,\n",
    "#         'trimean': float(trimean(x)) if x.size > 0 else np.nan,\n",
    "#         'std': float(np.std(x, ddof=1)) if x.size > 1 else np.nan,\n",
    "#         'IQR': float(iqr(x)) if x.size > 0 else np.nan,\n",
    "#         'MAD': float(mad(x)) if x.size > 0 else np.nan,\n",
    "#         'skewness': skewness_val,\n",
    "#         'yule_kendall': float(yule_kendall(x)) if x.size > 0 else np.nan\n",
    "#     }\n",
    "\n",
    "# # --- Example Usage (outside the function) ---\n",
    "# # Extract wet day rainfall data for each city using the correct columns and detection limit\n",
    "# perth_data = perth.loc[\n",
    "#     (perth[\"Rainfall amount (millimetres)\"].notna()) &\n",
    "#     (perth[\"Rainfall amount (millimetres)\"] >= DETECTION_LIMIT_MM),\n",
    "#     \"Rainfall amount (millimetres)\"\n",
    "# ]\n",
    "# brisbane_data = brisbane.loc[\n",
    "#     (brisbane[\"Rainfall amount (millimetres)\"].notna()) &\n",
    "#     (brisbane[\"Rainfall amount (millimetres)\"] >= DETECTION_LIMIT_MM),\n",
    "#     \"Rainfall amount (millimetres)\"\n",
    "# ]\n",
    "# melbourne_data = melbourne.loc[\n",
    "#     (melbourne[\"Rainfall amount (millimetres)\"].notna()) &\n",
    "#     (melbourne[\"Rainfall amount (millimetres)\"] >= DETECTION_LIMIT_MM),\n",
    "#     \"Rainfall amount (millimetres)\"\n",
    "# ]\n",
    "\n",
    "# summary_results = {\n",
    "#     'Perth': summarize(perth_data),\n",
    "#     'Brisbane': summarize(brisbane_data),\n",
    "#     'Melbourne': summarize(melbourne_data)\n",
    "# }\n",
    "\n",
    "# print(\"--- Summary Results ---\")\n",
    "# for city, stats_dict in summary_results.items():\n",
    "#     print(f\"\\nCity: {city}\")\n",
    "#     for stat, value in stats_dict.items():\n",
    "#         print(f\"  {stat}: {value:.3f}\" if isinstance(value, float) and not math.isnan(value) else f\"  {stat}: {value}\")\n",
    "# print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "648b5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models: Gaussian, Gamma, Weibull (and Lognormal as 4th)\n",
    "def fit_distributions(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    results = {}\n",
    "    # Gaussian\n",
    "    mu, sigma = stats.norm.fit(x)\n",
    "    results['Gaussian'] = {'dist': stats.norm, 'params': (mu, sigma)}\n",
    "    # Gamma (force loc=0)\n",
    "    k, loc, scale = stats.gamma.fit(x, floc=0)\n",
    "    results['Gamma'] = {'dist': stats.gamma, 'params': (k, 0, scale)}\n",
    "    # Weibull (weibull_min)\n",
    "    c, loc, scale = stats.weibull_min.fit(x, floc=0)\n",
    "    results['Weibull'] = {'dist': stats.weibull_min, 'params': (c, 0, scale)}\n",
    "    # Lognormal (extra)\n",
    "    shape, loc, scale = stats.lognorm.fit(x, floc=0)\n",
    "    results['Lognormal'] = {'dist': stats.lognorm, 'params': (shape, 0, scale)}\n",
    "    return results\n",
    "\n",
    "def log_likelihood(x, model):\n",
    "    dist = model['dist']\n",
    "    params = model['params']\n",
    "    pdf_vals = dist.pdf(x, *params)\n",
    "    pdf_vals = np.clip(pdf_vals, 1e-300, None)\n",
    "    return float(np.sum(np.log(pdf_vals)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
